{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # filter out info and warning messages\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vaB7cgLYx6be"
   },
   "outputs": [],
   "source": [
    "def deprocess_img(processed_img):\n",
    "    '''\n",
    "    Takes a preprocessed image used by VGG-16 and returns the corresponding original image. This is done\n",
    "    by adding the mean pixel values, reversing the color channel back to RGB and clipping the values. \n",
    "    Arguments: \n",
    "        processed_img:tensor\n",
    "            Preprocessed image in shape(1,224,224)\n",
    "    Returns: \n",
    "        img:tensor\n",
    "            Original image in tf.uint8 format with shape(224,224,3).\n",
    "    '''\n",
    "    imagenet_means = [103.939, 116.779, 123.68]\n",
    "    means = tf.reshape(tf.constant(imagenet_means), [1, 1, 3])\n",
    "    img = processed_img + means\n",
    "    img = tf.reverse(img, axis=[-1])\n",
    "    img = tf.clip_by_value(img, 0, 255)\n",
    "    img = tf.cast(img, tf.uint8)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKnTgYWwBNMn"
   },
   "outputs": [],
   "source": [
    "def show_example(img, sal_map):\n",
    "    '''\n",
    "    Display the image with its saliency map overlayed and both separately.\n",
    "    Three subplots are generated using matplotlib.\n",
    "    Arguments: \n",
    "        img:tensor\n",
    "            Preprocessed image.\n",
    "        sal_map:tensor\n",
    "            Saliency map corresponding to the input image.\n",
    "    '''\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(8, 4))\n",
    "\n",
    "    ax[0].imshow(deprocess_img(img))\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(sal_map, cmap='plasma', vmin=0, vmax=1) # plasma\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    ax[2].imshow(deprocess_img(img))\n",
    "    ax[2].imshow(sal_map, cmap='plasma', vmin=0, vmax=1, alpha=0.7, interpolation='bilinear') # plasma\n",
    "    ax[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "salicon_train_ds_path = f'./SALICON/tfds_salicon/train2014'\n",
    "salicon_train_ds = tf.data.Dataset.load(salicon_train_ds_path, compression='GZIP')\n",
    "\n",
    "# Show examples for 3 images of the train dataset\n",
    "for img, _, label in salicon_train_ds.take(3):\n",
    "    show_example(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "salicon_val_ds_path = f'./SALICON/tfds_salicon/val2014'\n",
    "salicon_val_ds = tf.data.Dataset.load(salicon_val_ds_path, compression='GZIP')\n",
    "\n",
    "# Show examples for 3 images of the validation dataset\n",
    "for img, _, sal_map in salicon_val_ds.take(3):\n",
    "    show_example(img, sal_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "capgaze1_ds_path = f'./capgaze1/tfds_capgaze1'\n",
    "capgaze1_ds = tf.data.Dataset.load(capgaze1_ds_path, compression='GZIP')\n",
    "\n",
    "# Show examples for 3 images of the capgaze dataset, which we use to test the ability of generalization\n",
    "for img, _, label in capgaze1_ds.take(3):\n",
    "    show_example(img, label)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "iannwtf",
   "language": "python",
   "name": "iannwtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
